{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "acceptability_classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "47880a60c6c54be78a00b9878eed0d78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ab13dcdabfb142c7b5d76b3a03c02da5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0a94dbbdf2654154be1de080377b7cd4",
              "IPY_MODEL_b04e871bf6b24963aedc508db798ce4a"
            ]
          }
        },
        "ab13dcdabfb142c7b5d76b3a03c02da5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0a94dbbdf2654154be1de080377b7cd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_af77efce74c247ed9a4784bea171c6e7",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 5069051,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5069051,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_56ff079a93cf4573b6c9c0b2ae6e3b93"
          }
        },
        "b04e871bf6b24963aedc508db798ce4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1b0c20ac83c7497f891ad42b3a674f13",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5.07M/5.07M [00:02&lt;00:00, 1.92MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ba5e87abc67745229aee270bd4b39ca9"
          }
        },
        "af77efce74c247ed9a4784bea171c6e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "56ff079a93cf4573b6c9c0b2ae6e3b93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1b0c20ac83c7497f891ad42b3a674f13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ba5e87abc67745229aee270bd4b39ca9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "97e4e04033b84edfbf9470fd5b3712b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_51407499189644618f48cc0c9d0bc636",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0df39c80a5d84be2b1b26ade9cafb763",
              "IPY_MODEL_4adcbd6cade24f88bef6d700e6103475"
            ]
          }
        },
        "51407499189644618f48cc0c9d0bc636": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0df39c80a5d84be2b1b26ade9cafb763": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_bd7249df8f82498b9ecd554eaea3fa07",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 9096718,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 9096718,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a5e4b2bce19a441b9fb541c5b430aa6d"
          }
        },
        "4adcbd6cade24f88bef6d700e6103475": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_52b3d8edaa254dcdbb415d7b2f6f2d8c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 9.10M/9.10M [00:04&lt;00:00, 2.03MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b4d1e02ecaa54d2b8a01dee6c1cadd89"
          }
        },
        "bd7249df8f82498b9ecd554eaea3fa07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a5e4b2bce19a441b9fb541c5b430aa6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "52b3d8edaa254dcdbb415d7b2f6f2d8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b4d1e02ecaa54d2b8a01dee6c1cadd89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "efa13f4808eb4e0cba37e70527552d32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4f480a667a2d4411a991da804cc19577",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b428864ecfc84480a2a8fe474f5e2692",
              "IPY_MODEL_9e2e92390f7c40ba96df0363962c005d"
            ]
          }
        },
        "4f480a667a2d4411a991da804cc19577": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b428864ecfc84480a2a8fe474f5e2692": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c152d5b93a3549809146cc4dd60630bd",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 513,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 513,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b80715db137745d3b40fc7746287af56"
          }
        },
        "9e2e92390f7c40ba96df0363962c005d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_724647323ec542f2a61e39391009f6d2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 513/513 [00:49&lt;00:00, 10.4B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_056b87eaa2df4aa5ac156e98db8de60e"
          }
        },
        "c152d5b93a3549809146cc4dd60630bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b80715db137745d3b40fc7746287af56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "724647323ec542f2a61e39391009f6d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "056b87eaa2df4aa5ac156e98db8de60e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3ac113dfb5dc451ebc485779b5b9b789": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_63827bf3dee24bed9fdd95b35a16a08c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_75f2695bc6464cd0be8f16546bce745a",
              "IPY_MODEL_e4e18b15c6ef47c18191a88c7c97f322"
            ]
          }
        },
        "63827bf3dee24bed9fdd95b35a16a08c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "75f2695bc6464cd0be8f16546bce745a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_076e6063b15a4097b4fabcbd427dbd22",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 2244861551,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2244861551,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_898dcca41d404922928e2dd9c04b1ba2"
          }
        },
        "e4e18b15c6ef47c18191a88c7c97f322": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_15403a2d02a74b6dacdaf377e732ce48",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2.24G/2.24G [00:47&lt;00:00, 47.3MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_aa601079fddf4712842a46a09deb19ac"
          }
        },
        "076e6063b15a4097b4fabcbd427dbd22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "898dcca41d404922928e2dd9c04b1ba2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "15403a2d02a74b6dacdaf377e732ce48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "aa601079fddf4712842a46a09deb19ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "iorCIFLWP3S4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e3a12fb-2022-4947-9b4f-6697c3f1c424"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install sentencepiece"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b0/9e/5b80becd952d5f7250eaf8fc64b957077b12ccfe73e9c03d37146ab29712/transformers-4.6.0-py3-none-any.whl (2.3MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 4.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Collecting huggingface-hub==0.0.8\n",
            "  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 44.1MB/s \n",
            "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 45.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (8.0.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Installing collected packages: huggingface-hub, sacremoses, tokenizers, transformers\n",
            "Successfully installed huggingface-hub-0.0.8 sacremoses-0.0.45 tokenizers-0.10.2 transformers-4.6.0\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 4.2MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.95\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJUnDFzgzC3q"
      },
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "#from transformers import BertTokenizer\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig, BertPreTrainedModel, BertModel , Adafactor\n",
        "from transformers import get_linear_schedule_with_warmup"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9Kg6I5oyC4j"
      },
      "source": [
        "from transformers import XLMForSequenceClassification , XLMRobertaTokenizerFast , XLMTokenizer , XLMRobertaForSequenceClassification"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcalmCCuTwcu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "540f98fa-3ae5-4a7a-ed93-eeebf74e34c0"
      },
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name == '/device:GPU:0':\n",
        "    print(f'Found GPU at: {device_name}')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLZLsS3fUli7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecb9f5cf-e111-4048-a6f2-5b6312f1d3cb"
      },
      "source": [
        "if torch.cuda.is_available():    \n",
        "    device = torch.device(\"cuda\")\n",
        "    print('GPU in use:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print('using the CPU')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU in use: Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IokttCXpR1_"
      },
      "source": [
        "# extra preprocessing steps\n",
        "# prepend CLS and append SEP, truncate, pad\n",
        "\n",
        "#parameters for the dataset and dataloader\n",
        "BATCH_SIZE = 32\n",
        "max_sent_length=128\n",
        "\n",
        "def preprocessing(df):\n",
        "    sentences = df.sentence.values\n",
        "    labels = np.array([ l for l in df.label.values])\n",
        "\n",
        "    tokenizer =XLMRobertaTokenizerFast.from_pretrained(\"xlm-roberta-large\" , do_lower_case=True )\n",
        "    \n",
        "    encoded_sentences = []\n",
        "    for sent in sentences:\n",
        "        encoded_sent = tokenizer.encode(\n",
        "                            sent,\n",
        "                            add_special_tokens = True,\n",
        "                            truncation=True,\n",
        "                            max_length = max_sent_length\n",
        "                    )\n",
        "        \n",
        "        encoded_sentences.append(encoded_sent)\n",
        "    #encoded_sentences = pad_sequences(encoded_sentences, maxlen=MAX_LEN, dtype=\"long\", \n",
        "    #                        value=0, truncating=\"post\", padding=\"post\")\n",
        "    \n",
        "    return encoded_sentences, labels\n",
        "    "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tPYOUwWu3gU"
      },
      "source": [
        "df = pd.read_csv(\"/content/in_domain_train.tsv\", \n",
        "                 delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
        "\n",
        "df_out = pd.read_csv(\"/content/out_of_domain_dev.tsv\", \n",
        "                 delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
        "\n",
        "df_test = pd.read_csv(\"/content/in_domain_dev.tsv\", \n",
        "                 delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ftdCfDpHRgz"
      },
      "source": [
        "df = pd.concat([df, df_out ], ignore_index=True, sort=False)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3FStGvIpttG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115,
          "referenced_widgets": [
            "47880a60c6c54be78a00b9878eed0d78",
            "ab13dcdabfb142c7b5d76b3a03c02da5",
            "0a94dbbdf2654154be1de080377b7cd4",
            "b04e871bf6b24963aedc508db798ce4a",
            "af77efce74c247ed9a4784bea171c6e7",
            "56ff079a93cf4573b6c9c0b2ae6e3b93",
            "1b0c20ac83c7497f891ad42b3a674f13",
            "ba5e87abc67745229aee270bd4b39ca9",
            "97e4e04033b84edfbf9470fd5b3712b6",
            "51407499189644618f48cc0c9d0bc636",
            "0df39c80a5d84be2b1b26ade9cafb763",
            "4adcbd6cade24f88bef6d700e6103475",
            "bd7249df8f82498b9ecd554eaea3fa07",
            "a5e4b2bce19a441b9fb541c5b430aa6d",
            "52b3d8edaa254dcdbb415d7b2f6f2d8c",
            "b4d1e02ecaa54d2b8a01dee6c1cadd89"
          ]
        },
        "outputId": "290cb0ce-731f-4cd7-8382-f96791555768"
      },
      "source": [
        "train_encoded_sentences, train_labels = preprocessing(df)\n",
        "test_encoded_sentences, test_labels = preprocessing(df_test)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "47880a60c6c54be78a00b9878eed0d78",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=5069051.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "97e4e04033b84edfbf9470fd5b3712b6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=9096718.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASNt6C1C4WJU"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class GrammerDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Class that represents a train/validation/test dataset that's readable for PyTorch\n",
        "    Note that this class inherits torch.utils.data.Dataset\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, data_list, target_list, max_sent_length=128):\n",
        "        \"\"\"\n",
        "        @param data_list: list of data tokens \n",
        "        @param target_list: list of data targets \n",
        "        \"\"\"\n",
        "        self.data_list = data_list\n",
        "        self.target_list = target_list\n",
        "        self.max_sent_length = max_sent_length\n",
        "        assert (len(self.data_list) == len(self.target_list))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_list)\n",
        "        \n",
        "    def __getitem__(self, key, max_sent_length=None):\n",
        "        \"\"\"\n",
        "        Triggered when you call dataset[i]\n",
        "        \"\"\"\n",
        "        if max_sent_length is None:\n",
        "            max_sent_length = self.max_sent_length\n",
        "        token_idx = self.data_list[key][:max_sent_length]\n",
        "        label = self.target_list[key]\n",
        "        return [token_idx, label]\n",
        "\n",
        "    def attention_masks(self , encoded_sentences):\n",
        "      # attention masks, 0 for padding, 1 for actual token\n",
        "      attention_masks = []\n",
        "      for sent in encoded_sentences:\n",
        "          att_mask = [int(token_id != 1 ) for token_id in sent]\n",
        "          attention_masks.append(att_mask)\n",
        "\n",
        "      return attention_masks\n",
        "\n",
        "    def spam_collate_func(self,batch):\n",
        "        \"\"\"\n",
        "        Customized function for DataLoader that dynamically pads the batch so that all \n",
        "        data have the same length\n",
        "        \"\"\" \n",
        "        data_list = [] \n",
        "        label_list = []\n",
        "        mask_list = []\n",
        "\n",
        "        max_batch_seq_len = None # the length of longest sequence in batch\n",
        "                                 # if it is less than self.max_sent_length\n",
        "                                 # else max_batch_seq_len = self.max_sent_length\n",
        "\n",
        "        \"\"\"\n",
        "          # Pad the sequences in your data \n",
        "          # if their length is less than max_batch_seq_len\n",
        "          # or trim the sequences that are longer than self.max_sent_length\n",
        "          # return padded data_list and label_list\n",
        "        \"\"\"\n",
        "        \n",
        "        # store the labels in label_list\n",
        "        label_list = [datum[1] for datum in batch]\n",
        "        # find the max sequence length from the batch\n",
        "        max_batch_seq_len = max(len(datum[0]) for datum in batch)\n",
        "\n",
        "        if max_batch_seq_len > self.max_sent_length:\n",
        "          max_batch_seq_len = self.max_sent_length\n",
        "\n",
        "        # pad each of the texts in batch\n",
        "        for datum in batch:\n",
        "          padded_vec = np.pad(np.array(datum[0]),\n",
        "                              pad_width = ((0, max_batch_seq_len - len(datum[0]))),\n",
        "                              mode = \"constant\", constant_values = 1)\n",
        "          \n",
        "          #generate the attention mask\n",
        "          attention_mask = self.attention_masks( [padded_vec] )\n",
        "\n",
        "          data_list.append(padded_vec)\n",
        "          mask_list.append( attention_mask[0] )\n",
        "\n",
        "\n",
        "        # convert to tensors\n",
        "        data_list = torch.from_numpy(np.array(data_list))\n",
        "        label_list = torch.LongTensor(label_list)\n",
        "        mask_list = torch.from_numpy(  np.array( mask_list ) )\n",
        "\n",
        "        return [data_list, mask_list , label_list]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEzfslfY8gah"
      },
      "source": [
        "train_dataset = GrammerDataset( train_encoded_sentences , train_labels, max_sent_length)\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
        "                                           batch_size=BATCH_SIZE,\n",
        "                                           collate_fn=train_dataset.spam_collate_func,\n",
        "                                           shuffle=True)\n",
        "\n",
        "\n",
        "valid_dataset = GrammerDataset( test_encoded_sentences , test_labels, train_dataset.max_sent_length)\n",
        "valid_loader = torch.utils.data.DataLoader(dataset=valid_dataset, \n",
        "                                           batch_size=BATCH_SIZE,\n",
        "                                           collate_fn=train_dataset.spam_collate_func,\n",
        "                                           shuffle=False)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xON2LLwOxpiB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220,
          "referenced_widgets": [
            "efa13f4808eb4e0cba37e70527552d32",
            "4f480a667a2d4411a991da804cc19577",
            "b428864ecfc84480a2a8fe474f5e2692",
            "9e2e92390f7c40ba96df0363962c005d",
            "c152d5b93a3549809146cc4dd60630bd",
            "b80715db137745d3b40fc7746287af56",
            "724647323ec542f2a61e39391009f6d2",
            "056b87eaa2df4aa5ac156e98db8de60e",
            "3ac113dfb5dc451ebc485779b5b9b789",
            "63827bf3dee24bed9fdd95b35a16a08c",
            "75f2695bc6464cd0be8f16546bce745a",
            "e4e18b15c6ef47c18191a88c7c97f322",
            "076e6063b15a4097b4fabcbd427dbd22",
            "898dcca41d404922928e2dd9c04b1ba2",
            "15403a2d02a74b6dacdaf377e732ce48",
            "aa601079fddf4712842a46a09deb19ac"
          ]
        },
        "outputId": "53923aa7-894f-4e22-9e78-a51f8c238b1f"
      },
      "source": [
        "import random\n",
        "\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "\n",
        "\n",
        "model = XLMRobertaForSequenceClassification.from_pretrained( \"xlm-roberta-large\" , \n",
        "                             num_labels = 2 ,   \n",
        "                             output_attentions = False, \n",
        "                             output_hidden_states = False,    )\n",
        "\n",
        "model.cuda()\n",
        "\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 1e-5, \n",
        "                  eps = 1e-8, \n",
        "                  weight_decay = 0.01\n",
        "                )\n",
        "\n",
        "\"\"\"\n",
        "optimizer = Adafactor( model.parameters(),\n",
        "                      lr=1e-5,\n",
        "                      eps=(1e-30, 1e-3),\n",
        "                      clip_threshold=1.0,\n",
        "                      decay_rate=-0.8,\n",
        "                      beta1=None,\n",
        "                      weight_decay=0.01,\n",
        "                      relative_step=False,\n",
        "                      scale_parameter=False,\n",
        "                      warmup_init=False\n",
        ")\n",
        "\n",
        "\"\"\"\n",
        "epochs = 20\n",
        "total_steps = len(train_loader) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0 , # 10% * datasetSize/batchSize\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "efa13f4808eb4e0cba37e70527552d32",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=513.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3ac113dfb5dc451ebc485779b5b9b789",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=2244861551.0, style=ProgressStyle(descr…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at xlm-roberta-large were not used when initializing XLMRobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'roberta.pooler.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.decoder.weight']\n",
            "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-large and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFBW9Sko_KcK",
        "outputId": "8d506007-7628-48cd-877a-4dced77b4374"
      },
      "source": [
        "model"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XLMRobertaForSequenceClassification(\n",
              "  (roberta): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(250002, 1024, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 1024)\n",
              "      (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): RobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (12): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (13): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (14): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (15): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (16): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (17): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (18): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (19): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (20): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (21): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (22): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (23): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (classifier): RobertaClassificationHead(\n",
              "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (out_proj): Linear(in_features=1024, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZL4pCBWMH6E"
      },
      "source": [
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "def compute_accuracy(preds, labels):\n",
        "    p = np.argmax(preds, axis=1).flatten()\n",
        "    l = labels.flatten()\n",
        "    return np.sum(p==l)/len(l)\n",
        "\n",
        "def run_train(epochs):\n",
        "\n",
        "    losses = []\n",
        "\n",
        "    for e in range(epochs):\n",
        "\n",
        "        print('======== Epoch {:} / {:} ========'.format(e + 1, epochs))\n",
        "        start_train_time = time.time()\n",
        "        total_loss = 0\n",
        "        model.train()\n",
        "        for step, batch in enumerate(train_loader):\n",
        "\n",
        "            if step%10 == 0:\n",
        "                elapsed = time.time()-start_train_time\n",
        "                print(f'{step}/{len(train_loader)} --> Time elapsed {elapsed}')\n",
        "\n",
        "            # input_data, input_masks, input_labels = batch\n",
        "            input_data = batch[0].to(device)\n",
        "            input_masks = batch[1].to(device)\n",
        "            input_labels = batch[2].to(device)\n",
        "\n",
        "            model.zero_grad()\n",
        "\n",
        "            # forward propagation\n",
        "            out = model(input_data,\n",
        "                        token_type_ids = None, \n",
        "                        attention_mask = input_masks,\n",
        "                        labels = input_labels)\n",
        "            \n",
        "            loss = out[0]\n",
        "            total_loss = total_loss + loss.item()\n",
        "\n",
        "            # backward propagation\n",
        "            loss.backward()\n",
        "            \n",
        "            torch.nn.utils.clip_grad_norm(model.parameters(), 1)\n",
        "\n",
        "            optimizer.step()\n",
        "        \n",
        "        epoch_loss = total_loss/len(train_loader)\n",
        "        losses.append(epoch_loss)\n",
        "        print(f\"Training took {time.time()-start_train_time}\")\n",
        "\n",
        "        # Validation\n",
        "        start_validation_time = time.time()\n",
        "        model.eval()\n",
        "        eval_loss, eval_acc = 0,0\n",
        "        for step, batch in enumerate(valid_loader):\n",
        "            batch = tuple(t.to(device) for t in batch)\n",
        "            eval_data, eval_masks, eval_labels = batch\n",
        "            with torch.no_grad():\n",
        "                out = model(eval_data,\n",
        "                            token_type_ids = None, \n",
        "                            attention_mask=eval_masks)\n",
        "            logits = out[0]\n",
        "\n",
        "            #  Uncomment for GPU execution\n",
        "            logits = logits.detach().cpu().numpy()\n",
        "            eval_labels = eval_labels.to('cpu').numpy()\n",
        "            batch_acc = compute_accuracy(logits, eval_labels)\n",
        "\n",
        "            # Uncomment for CPU execution\n",
        "            # batch_acc = compute_accuracy(logits.numpy(), eval_labels.numpy())\n",
        "\n",
        "            eval_acc += batch_acc\n",
        "        print(f\"Accuracy: {eval_acc/(step+1)}, Time elapsed: {time.time()-start_validation_time}\")\n",
        "    return losses\n",
        "            "
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAILAFFrTFhq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0437074e-aa8f-492a-cdc3-710cebd69d6f"
      },
      "source": [
        "losses = run_train(epochs)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "======== Epoch 1 / 20 ========\n",
            "0/284 --> Time elapsed 0.03030109405517578\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:43: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10/284 --> Time elapsed 4.548385143280029\n",
            "20/284 --> Time elapsed 8.43670916557312\n",
            "30/284 --> Time elapsed 12.567052364349365\n",
            "40/284 --> Time elapsed 16.186969757080078\n",
            "50/284 --> Time elapsed 20.17724633216858\n",
            "60/284 --> Time elapsed 24.175666570663452\n",
            "70/284 --> Time elapsed 28.119767427444458\n",
            "80/284 --> Time elapsed 31.978269815444946\n",
            "90/284 --> Time elapsed 35.9216034412384\n",
            "100/284 --> Time elapsed 39.55854940414429\n",
            "110/284 --> Time elapsed 43.438857078552246\n",
            "120/284 --> Time elapsed 47.393128871917725\n",
            "130/284 --> Time elapsed 51.0744514465332\n",
            "140/284 --> Time elapsed 54.93984866142273\n",
            "150/284 --> Time elapsed 58.45712184906006\n",
            "160/284 --> Time elapsed 62.38796854019165\n",
            "170/284 --> Time elapsed 66.03950476646423\n",
            "180/284 --> Time elapsed 69.81658816337585\n",
            "190/284 --> Time elapsed 73.38852214813232\n",
            "200/284 --> Time elapsed 77.1658673286438\n",
            "210/284 --> Time elapsed 81.23037600517273\n",
            "220/284 --> Time elapsed 85.20038890838623\n",
            "230/284 --> Time elapsed 89.08843731880188\n",
            "240/284 --> Time elapsed 92.6084725856781\n",
            "250/284 --> Time elapsed 96.31035256385803\n",
            "260/284 --> Time elapsed 99.95278978347778\n",
            "270/284 --> Time elapsed 103.79999852180481\n",
            "280/284 --> Time elapsed 107.49941396713257\n",
            "Training took 108.8453893661499\n",
            "Accuracy: 0.8225490196078431, Time elapsed: 1.3235485553741455\n",
            "======== Epoch 2 / 20 ========\n",
            "0/284 --> Time elapsed 0.003717660903930664\n",
            "10/284 --> Time elapsed 3.6246869564056396\n",
            "20/284 --> Time elapsed 7.371434688568115\n",
            "30/284 --> Time elapsed 11.392065048217773\n",
            "40/284 --> Time elapsed 15.05561351776123\n",
            "50/284 --> Time elapsed 18.87796425819397\n",
            "60/284 --> Time elapsed 22.783891916275024\n",
            "70/284 --> Time elapsed 26.58191967010498\n",
            "80/284 --> Time elapsed 30.38565993309021\n",
            "90/284 --> Time elapsed 34.33539581298828\n",
            "100/284 --> Time elapsed 37.97958254814148\n",
            "110/284 --> Time elapsed 41.92292404174805\n",
            "120/284 --> Time elapsed 45.627238750457764\n",
            "130/284 --> Time elapsed 49.247626066207886\n",
            "140/284 --> Time elapsed 52.848976850509644\n",
            "150/284 --> Time elapsed 56.53601551055908\n",
            "160/284 --> Time elapsed 60.43808460235596\n",
            "170/284 --> Time elapsed 64.14252400398254\n",
            "180/284 --> Time elapsed 67.95504474639893\n",
            "190/284 --> Time elapsed 71.84545421600342\n",
            "200/284 --> Time elapsed 75.82213091850281\n",
            "210/284 --> Time elapsed 79.37887215614319\n",
            "220/284 --> Time elapsed 83.0296425819397\n",
            "230/284 --> Time elapsed 86.85205078125\n",
            "240/284 --> Time elapsed 90.6818995475769\n",
            "250/284 --> Time elapsed 94.52557921409607\n",
            "260/284 --> Time elapsed 98.43995976448059\n",
            "270/284 --> Time elapsed 102.39218783378601\n",
            "280/284 --> Time elapsed 106.1650288105011\n",
            "Training took 107.60061120986938\n",
            "Accuracy: 0.8579656862745099, Time elapsed: 1.325751543045044\n",
            "======== Epoch 3 / 20 ========\n",
            "0/284 --> Time elapsed 0.005476474761962891\n",
            "10/284 --> Time elapsed 3.5890958309173584\n",
            "20/284 --> Time elapsed 7.329322099685669\n",
            "30/284 --> Time elapsed 10.999737739562988\n",
            "40/284 --> Time elapsed 14.884107112884521\n",
            "50/284 --> Time elapsed 18.510477781295776\n",
            "60/284 --> Time elapsed 22.42654323577881\n",
            "70/284 --> Time elapsed 26.410228490829468\n",
            "80/284 --> Time elapsed 30.406937837600708\n",
            "90/284 --> Time elapsed 34.034082651138306\n",
            "100/284 --> Time elapsed 37.70578145980835\n",
            "110/284 --> Time elapsed 41.4418568611145\n",
            "120/284 --> Time elapsed 45.38025999069214\n",
            "130/284 --> Time elapsed 49.165605306625366\n",
            "140/284 --> Time elapsed 52.999653339385986\n",
            "150/284 --> Time elapsed 56.63984560966492\n",
            "160/284 --> Time elapsed 60.313316822052\n",
            "170/284 --> Time elapsed 64.28091430664062\n",
            "180/284 --> Time elapsed 68.20871663093567\n",
            "190/284 --> Time elapsed 72.13990759849548\n",
            "200/284 --> Time elapsed 75.88008832931519\n",
            "210/284 --> Time elapsed 79.84821462631226\n",
            "220/284 --> Time elapsed 83.90356826782227\n",
            "230/284 --> Time elapsed 87.99777340888977\n",
            "240/284 --> Time elapsed 91.83143544197083\n",
            "250/284 --> Time elapsed 95.47315645217896\n",
            "260/284 --> Time elapsed 99.31024885177612\n",
            "270/284 --> Time elapsed 103.01608490943909\n",
            "280/284 --> Time elapsed 107.15485167503357\n",
            "Training took 108.443354845047\n",
            "Accuracy: 0.8462009803921569, Time elapsed: 1.3237404823303223\n",
            "======== Epoch 4 / 20 ========\n",
            "0/284 --> Time elapsed 0.00615692138671875\n",
            "10/284 --> Time elapsed 3.5992794036865234\n",
            "20/284 --> Time elapsed 7.37686562538147\n",
            "30/284 --> Time elapsed 10.997358798980713\n",
            "40/284 --> Time elapsed 14.831858396530151\n",
            "50/284 --> Time elapsed 18.8233482837677\n",
            "60/284 --> Time elapsed 22.77724575996399\n",
            "70/284 --> Time elapsed 26.608651399612427\n",
            "80/284 --> Time elapsed 30.36673903465271\n",
            "90/284 --> Time elapsed 33.987661838531494\n",
            "100/284 --> Time elapsed 37.6855525970459\n",
            "110/284 --> Time elapsed 41.2716851234436\n",
            "120/284 --> Time elapsed 45.27038335800171\n",
            "130/284 --> Time elapsed 49.16431140899658\n",
            "140/284 --> Time elapsed 53.048733711242676\n",
            "150/284 --> Time elapsed 56.9584584236145\n",
            "160/284 --> Time elapsed 60.78249526023865\n",
            "170/284 --> Time elapsed 64.2500867843628\n",
            "180/284 --> Time elapsed 68.20227074623108\n",
            "190/284 --> Time elapsed 71.94167923927307\n",
            "200/284 --> Time elapsed 75.77681016921997\n",
            "210/284 --> Time elapsed 79.7846462726593\n",
            "220/284 --> Time elapsed 83.70650696754456\n",
            "230/284 --> Time elapsed 87.64330530166626\n",
            "240/284 --> Time elapsed 91.30617952346802\n",
            "250/284 --> Time elapsed 95.24348258972168\n",
            "260/284 --> Time elapsed 99.25190353393555\n",
            "270/284 --> Time elapsed 103.03968977928162\n",
            "280/284 --> Time elapsed 106.68847870826721\n",
            "Training took 108.07576370239258\n",
            "Accuracy: 0.8689950980392157, Time elapsed: 1.3253753185272217\n",
            "======== Epoch 5 / 20 ========\n",
            "0/284 --> Time elapsed 0.0039021968841552734\n",
            "10/284 --> Time elapsed 3.6632297039031982\n",
            "20/284 --> Time elapsed 7.4523842334747314\n",
            "30/284 --> Time elapsed 11.374098777770996\n",
            "40/284 --> Time elapsed 15.24346661567688\n",
            "50/284 --> Time elapsed 18.9454665184021\n",
            "60/284 --> Time elapsed 22.87322974205017\n",
            "70/284 --> Time elapsed 26.565216302871704\n",
            "80/284 --> Time elapsed 30.20438313484192\n",
            "90/284 --> Time elapsed 34.03254151344299\n",
            "100/284 --> Time elapsed 38.11802816390991\n",
            "110/284 --> Time elapsed 42.21867656707764\n",
            "120/284 --> Time elapsed 46.09648656845093\n",
            "130/284 --> Time elapsed 49.86718559265137\n",
            "140/284 --> Time elapsed 53.47470307350159\n",
            "150/284 --> Time elapsed 57.27031087875366\n",
            "160/284 --> Time elapsed 61.11428666114807\n",
            "170/284 --> Time elapsed 64.74064898490906\n",
            "180/284 --> Time elapsed 68.50630283355713\n",
            "190/284 --> Time elapsed 72.40361499786377\n",
            "200/284 --> Time elapsed 76.11285734176636\n",
            "210/284 --> Time elapsed 80.40878629684448\n",
            "220/284 --> Time elapsed 83.9476728439331\n",
            "230/284 --> Time elapsed 87.76383638381958\n",
            "240/284 --> Time elapsed 91.65760231018066\n",
            "250/284 --> Time elapsed 95.5329225063324\n",
            "260/284 --> Time elapsed 99.30956697463989\n",
            "270/284 --> Time elapsed 103.03151607513428\n",
            "280/284 --> Time elapsed 106.63368511199951\n",
            "Training took 107.93086194992065\n",
            "Accuracy: 0.8689950980392157, Time elapsed: 1.3254103660583496\n",
            "======== Epoch 6 / 20 ========\n",
            "0/284 --> Time elapsed 0.004933357238769531\n",
            "10/284 --> Time elapsed 3.6995115280151367\n",
            "20/284 --> Time elapsed 7.703740835189819\n",
            "30/284 --> Time elapsed 11.402115821838379\n",
            "40/284 --> Time elapsed 15.191770792007446\n",
            "50/284 --> Time elapsed 19.277381658554077\n",
            "60/284 --> Time elapsed 22.971627950668335\n",
            "70/284 --> Time elapsed 26.865464448928833\n",
            "80/284 --> Time elapsed 30.479658603668213\n",
            "90/284 --> Time elapsed 34.55163884162903\n",
            "100/284 --> Time elapsed 38.55168151855469\n",
            "110/284 --> Time elapsed 42.13248634338379\n",
            "120/284 --> Time elapsed 45.7410147190094\n",
            "130/284 --> Time elapsed 49.471757888793945\n",
            "140/284 --> Time elapsed 53.13381862640381\n",
            "150/284 --> Time elapsed 56.88392615318298\n",
            "160/284 --> Time elapsed 60.733806848526\n",
            "170/284 --> Time elapsed 64.85288715362549\n",
            "180/284 --> Time elapsed 68.6034529209137\n",
            "190/284 --> Time elapsed 72.5246729850769\n",
            "200/284 --> Time elapsed 76.41398239135742\n",
            "210/284 --> Time elapsed 80.03667998313904\n",
            "220/284 --> Time elapsed 83.94508838653564\n",
            "230/284 --> Time elapsed 87.65384793281555\n",
            "240/284 --> Time elapsed 91.18317794799805\n",
            "250/284 --> Time elapsed 94.97010087966919\n",
            "260/284 --> Time elapsed 98.76920080184937\n",
            "270/284 --> Time elapsed 102.50046801567078\n",
            "280/284 --> Time elapsed 106.25217771530151\n",
            "Training took 107.67605471611023\n",
            "Accuracy: 0.8705882352941177, Time elapsed: 1.3241050243377686\n",
            "======== Epoch 7 / 20 ========\n",
            "0/284 --> Time elapsed 0.004979133605957031\n",
            "10/284 --> Time elapsed 4.09862756729126\n",
            "20/284 --> Time elapsed 7.821072816848755\n",
            "30/284 --> Time elapsed 11.768748044967651\n",
            "40/284 --> Time elapsed 15.538573741912842\n",
            "50/284 --> Time elapsed 19.429404735565186\n",
            "60/284 --> Time elapsed 23.05020499229431\n",
            "70/284 --> Time elapsed 26.88366436958313\n",
            "80/284 --> Time elapsed 30.531328916549683\n",
            "90/284 --> Time elapsed 34.2191207408905\n",
            "100/284 --> Time elapsed 37.844825744628906\n",
            "110/284 --> Time elapsed 41.8960235118866\n",
            "120/284 --> Time elapsed 45.63333868980408\n",
            "130/284 --> Time elapsed 49.36401414871216\n",
            "140/284 --> Time elapsed 53.070454597473145\n",
            "150/284 --> Time elapsed 57.007943868637085\n",
            "160/284 --> Time elapsed 60.939817667007446\n",
            "170/284 --> Time elapsed 64.83001756668091\n",
            "180/284 --> Time elapsed 68.60044026374817\n",
            "190/284 --> Time elapsed 72.2035186290741\n",
            "200/284 --> Time elapsed 76.0426299571991\n",
            "210/284 --> Time elapsed 80.07760071754456\n",
            "220/284 --> Time elapsed 83.78685688972473\n",
            "230/284 --> Time elapsed 87.69805955886841\n",
            "240/284 --> Time elapsed 91.26837420463562\n",
            "250/284 --> Time elapsed 95.17127823829651\n",
            "260/284 --> Time elapsed 99.12727808952332\n",
            "270/284 --> Time elapsed 103.37043523788452\n",
            "280/284 --> Time elapsed 107.11751317977905\n",
            "Training took 108.39382481575012\n",
            "Accuracy: 0.8577205882352942, Time elapsed: 1.324394702911377\n",
            "======== Epoch 8 / 20 ========\n",
            "0/284 --> Time elapsed 0.005089998245239258\n",
            "10/284 --> Time elapsed 3.6971585750579834\n",
            "20/284 --> Time elapsed 7.6826558113098145\n",
            "30/284 --> Time elapsed 11.718130350112915\n",
            "40/284 --> Time elapsed 15.382147550582886\n",
            "50/284 --> Time elapsed 19.099961042404175\n",
            "60/284 --> Time elapsed 22.84487509727478\n",
            "70/284 --> Time elapsed 26.765623807907104\n",
            "80/284 --> Time elapsed 30.704329252243042\n",
            "90/284 --> Time elapsed 34.46943545341492\n",
            "100/284 --> Time elapsed 38.38001084327698\n",
            "110/284 --> Time elapsed 42.27546763420105\n",
            "120/284 --> Time elapsed 45.97499895095825\n",
            "130/284 --> Time elapsed 49.665976762771606\n",
            "140/284 --> Time elapsed 53.3202691078186\n",
            "150/284 --> Time elapsed 56.92987775802612\n",
            "160/284 --> Time elapsed 60.921016693115234\n",
            "170/284 --> Time elapsed 64.6512999534607\n",
            "180/284 --> Time elapsed 68.21926212310791\n",
            "190/284 --> Time elapsed 71.96165013313293\n",
            "200/284 --> Time elapsed 75.54323244094849\n",
            "210/284 --> Time elapsed 79.35692620277405\n",
            "220/284 --> Time elapsed 83.33064460754395\n",
            "230/284 --> Time elapsed 86.99568605422974\n",
            "240/284 --> Time elapsed 90.54566693305969\n",
            "250/284 --> Time elapsed 94.41471552848816\n",
            "260/284 --> Time elapsed 98.24003744125366\n",
            "270/284 --> Time elapsed 102.25516104698181\n",
            "280/284 --> Time elapsed 106.18215084075928\n",
            "Training took 107.54446959495544\n",
            "Accuracy: 0.8519607843137255, Time elapsed: 1.3232812881469727\n",
            "======== Epoch 9 / 20 ========\n",
            "0/284 --> Time elapsed 0.0047817230224609375\n",
            "10/284 --> Time elapsed 3.987558364868164\n",
            "20/284 --> Time elapsed 7.811807870864868\n",
            "30/284 --> Time elapsed 11.932864665985107\n",
            "40/284 --> Time elapsed 15.458703517913818\n",
            "50/284 --> Time elapsed 19.117743730545044\n",
            "60/284 --> Time elapsed 22.757418870925903\n",
            "70/284 --> Time elapsed 26.668817043304443\n",
            "80/284 --> Time elapsed 30.400410413742065\n",
            "90/284 --> Time elapsed 34.33206748962402\n",
            "100/284 --> Time elapsed 37.97063851356506\n",
            "110/284 --> Time elapsed 41.792943716049194\n",
            "120/284 --> Time elapsed 45.36761021614075\n",
            "130/284 --> Time elapsed 48.80097246170044\n",
            "140/284 --> Time elapsed 52.43811655044556\n",
            "150/284 --> Time elapsed 56.5236976146698\n",
            "160/284 --> Time elapsed 60.244248390197754\n",
            "170/284 --> Time elapsed 64.06688833236694\n",
            "180/284 --> Time elapsed 67.96662402153015\n",
            "190/284 --> Time elapsed 71.75671029090881\n",
            "200/284 --> Time elapsed 75.58186626434326\n",
            "210/284 --> Time elapsed 79.23973202705383\n",
            "220/284 --> Time elapsed 83.19658041000366\n",
            "230/284 --> Time elapsed 86.8440592288971\n",
            "240/284 --> Time elapsed 90.54242968559265\n",
            "250/284 --> Time elapsed 94.59625220298767\n",
            "260/284 --> Time elapsed 98.33132147789001\n",
            "270/284 --> Time elapsed 102.20355463027954\n",
            "280/284 --> Time elapsed 105.91991877555847\n",
            "Training took 107.40666246414185\n",
            "Accuracy: 0.8446078431372549, Time elapsed: 1.3229014873504639\n",
            "======== Epoch 10 / 20 ========\n",
            "0/284 --> Time elapsed 0.0038552284240722656\n",
            "10/284 --> Time elapsed 3.591719150543213\n",
            "20/284 --> Time elapsed 7.403907060623169\n",
            "30/284 --> Time elapsed 11.08507490158081\n",
            "40/284 --> Time elapsed 14.670016765594482\n",
            "50/284 --> Time elapsed 18.340433597564697\n",
            "60/284 --> Time elapsed 22.114818334579468\n",
            "70/284 --> Time elapsed 26.061968326568604\n",
            "80/284 --> Time elapsed 29.667975187301636\n",
            "90/284 --> Time elapsed 33.74773669242859\n",
            "100/284 --> Time elapsed 37.72708487510681\n",
            "110/284 --> Time elapsed 41.16690111160278\n",
            "120/284 --> Time elapsed 44.973435401916504\n",
            "130/284 --> Time elapsed 48.78354573249817\n",
            "140/284 --> Time elapsed 52.34567093849182\n",
            "150/284 --> Time elapsed 56.28698182106018\n",
            "160/284 --> Time elapsed 59.894434213638306\n",
            "170/284 --> Time elapsed 63.70267605781555\n",
            "180/284 --> Time elapsed 67.45128536224365\n",
            "190/284 --> Time elapsed 71.20417809486389\n",
            "200/284 --> Time elapsed 74.92807078361511\n",
            "210/284 --> Time elapsed 78.86408710479736\n",
            "220/284 --> Time elapsed 82.61389803886414\n",
            "230/284 --> Time elapsed 86.40357804298401\n",
            "240/284 --> Time elapsed 90.08598685264587\n",
            "250/284 --> Time elapsed 94.10458874702454\n",
            "260/284 --> Time elapsed 98.10492706298828\n",
            "270/284 --> Time elapsed 102.0617516040802\n",
            "280/284 --> Time elapsed 106.10811877250671\n",
            "Training took 107.49883556365967\n",
            "Accuracy: 0.8572303921568627, Time elapsed: 1.3213744163513184\n",
            "======== Epoch 11 / 20 ========\n",
            "0/284 --> Time elapsed 0.004468679428100586\n",
            "10/284 --> Time elapsed 3.6307294368743896\n",
            "20/284 --> Time elapsed 7.332539081573486\n",
            "30/284 --> Time elapsed 11.16637921333313\n",
            "40/284 --> Time elapsed 14.92164397239685\n",
            "50/284 --> Time elapsed 18.68164587020874\n",
            "60/284 --> Time elapsed 22.756256341934204\n",
            "70/284 --> Time elapsed 26.455864667892456\n",
            "80/284 --> Time elapsed 30.10434365272522\n",
            "90/284 --> Time elapsed 33.912338972091675\n",
            "100/284 --> Time elapsed 37.99160194396973\n",
            "110/284 --> Time elapsed 42.109782457351685\n",
            "120/284 --> Time elapsed 45.73551106452942\n",
            "130/284 --> Time elapsed 49.43539643287659\n",
            "140/284 --> Time elapsed 53.18108820915222\n",
            "150/284 --> Time elapsed 56.80528545379639\n",
            "160/284 --> Time elapsed 60.70852828025818\n",
            "170/284 --> Time elapsed 64.48840308189392\n",
            "180/284 --> Time elapsed 68.31718921661377\n",
            "190/284 --> Time elapsed 71.92918229103088\n",
            "200/284 --> Time elapsed 75.69145274162292\n",
            "210/284 --> Time elapsed 79.48963379859924\n",
            "220/284 --> Time elapsed 83.16923785209656\n",
            "230/284 --> Time elapsed 86.69122219085693\n",
            "240/284 --> Time elapsed 90.31817388534546\n",
            "250/284 --> Time elapsed 94.01707696914673\n",
            "260/284 --> Time elapsed 97.69976329803467\n",
            "270/284 --> Time elapsed 101.57792210578918\n",
            "280/284 --> Time elapsed 105.5441722869873\n",
            "Training took 106.88714742660522\n",
            "Accuracy: 0.868014705882353, Time elapsed: 1.322749376296997\n",
            "======== Epoch 12 / 20 ========\n",
            "0/284 --> Time elapsed 0.004946231842041016\n",
            "10/284 --> Time elapsed 3.585000991821289\n",
            "20/284 --> Time elapsed 7.197672605514526\n",
            "30/284 --> Time elapsed 10.77802586555481\n",
            "40/284 --> Time elapsed 14.618493795394897\n",
            "50/284 --> Time elapsed 18.50789785385132\n",
            "60/284 --> Time elapsed 22.345086336135864\n",
            "70/284 --> Time elapsed 26.223564863204956\n",
            "80/284 --> Time elapsed 29.861019611358643\n",
            "90/284 --> Time elapsed 33.601524353027344\n",
            "100/284 --> Time elapsed 37.30755853652954\n",
            "110/284 --> Time elapsed 41.03294253349304\n",
            "120/284 --> Time elapsed 44.69204783439636\n",
            "130/284 --> Time elapsed 48.65894365310669\n",
            "140/284 --> Time elapsed 52.418233156204224\n",
            "150/284 --> Time elapsed 56.1681923866272\n",
            "160/284 --> Time elapsed 59.94150257110596\n",
            "170/284 --> Time elapsed 63.731523275375366\n",
            "180/284 --> Time elapsed 67.89319133758545\n",
            "190/284 --> Time elapsed 71.6631247997284\n",
            "200/284 --> Time elapsed 75.48130679130554\n",
            "210/284 --> Time elapsed 79.16504454612732\n",
            "220/284 --> Time elapsed 82.83523344993591\n",
            "230/284 --> Time elapsed 86.75135779380798\n",
            "240/284 --> Time elapsed 90.7869324684143\n",
            "250/284 --> Time elapsed 94.53640365600586\n",
            "260/284 --> Time elapsed 98.23684692382812\n",
            "270/284 --> Time elapsed 102.19373726844788\n",
            "280/284 --> Time elapsed 106.00439620018005\n",
            "Training took 107.27646136283875\n",
            "Accuracy: 0.8661764705882353, Time elapsed: 1.3223176002502441\n",
            "======== Epoch 13 / 20 ========\n",
            "0/284 --> Time elapsed 0.0034530162811279297\n",
            "10/284 --> Time elapsed 3.490018367767334\n",
            "20/284 --> Time elapsed 7.342291593551636\n",
            "30/284 --> Time elapsed 11.053104162216187\n",
            "40/284 --> Time elapsed 14.890261888504028\n",
            "50/284 --> Time elapsed 18.672723293304443\n",
            "60/284 --> Time elapsed 22.43512201309204\n",
            "70/284 --> Time elapsed 26.02409529685974\n",
            "80/284 --> Time elapsed 29.760876178741455\n",
            "90/284 --> Time elapsed 33.573943853378296\n",
            "100/284 --> Time elapsed 37.142467975616455\n",
            "110/284 --> Time elapsed 40.89103937149048\n",
            "120/284 --> Time elapsed 44.89361262321472\n",
            "130/284 --> Time elapsed 48.754045724868774\n",
            "140/284 --> Time elapsed 52.63046717643738\n",
            "150/284 --> Time elapsed 56.194613456726074\n",
            "160/284 --> Time elapsed 59.99582099914551\n",
            "170/284 --> Time elapsed 63.878031492233276\n",
            "180/284 --> Time elapsed 67.43081402778625\n",
            "190/284 --> Time elapsed 71.23291897773743\n",
            "200/284 --> Time elapsed 75.11313319206238\n",
            "210/284 --> Time elapsed 78.94799780845642\n",
            "220/284 --> Time elapsed 82.72230505943298\n",
            "230/284 --> Time elapsed 86.73463845252991\n",
            "240/284 --> Time elapsed 90.67979598045349\n",
            "250/284 --> Time elapsed 94.22610545158386\n",
            "260/284 --> Time elapsed 97.95408129692078\n",
            "270/284 --> Time elapsed 101.71736311912537\n",
            "280/284 --> Time elapsed 105.46367573738098\n",
            "Training took 106.73573112487793\n",
            "Accuracy: 0.856985294117647, Time elapsed: 1.3231744766235352\n",
            "======== Epoch 14 / 20 ========\n",
            "0/284 --> Time elapsed 0.003869771957397461\n",
            "10/284 --> Time elapsed 3.6703743934631348\n",
            "20/284 --> Time elapsed 7.510738849639893\n",
            "30/284 --> Time elapsed 11.61815881729126\n",
            "40/284 --> Time elapsed 15.35488772392273\n",
            "50/284 --> Time elapsed 18.96466588973999\n",
            "60/284 --> Time elapsed 22.489124298095703\n",
            "70/284 --> Time elapsed 26.418115615844727\n",
            "80/284 --> Time elapsed 30.109949111938477\n",
            "90/284 --> Time elapsed 34.088234424591064\n",
            "100/284 --> Time elapsed 37.78521513938904\n",
            "110/284 --> Time elapsed 41.42243051528931\n",
            "120/284 --> Time elapsed 45.2752046585083\n",
            "130/284 --> Time elapsed 49.14164733886719\n",
            "140/284 --> Time elapsed 52.6403694152832\n",
            "150/284 --> Time elapsed 56.484575510025024\n",
            "160/284 --> Time elapsed 60.06284284591675\n",
            "170/284 --> Time elapsed 63.658395528793335\n",
            "180/284 --> Time elapsed 67.26751756668091\n",
            "190/284 --> Time elapsed 71.17124247550964\n",
            "200/284 --> Time elapsed 74.8206057548523\n",
            "210/284 --> Time elapsed 78.46207165718079\n",
            "220/284 --> Time elapsed 82.05141377449036\n",
            "230/284 --> Time elapsed 85.79449963569641\n",
            "240/284 --> Time elapsed 89.72900795936584\n",
            "250/284 --> Time elapsed 93.56669592857361\n",
            "260/284 --> Time elapsed 97.43800759315491\n",
            "270/284 --> Time elapsed 101.47086572647095\n",
            "280/284 --> Time elapsed 105.11306691169739\n",
            "Training took 106.52681756019592\n",
            "Accuracy: 0.8682598039215685, Time elapsed: 1.3217058181762695\n",
            "======== Epoch 15 / 20 ========\n",
            "0/284 --> Time elapsed 0.004107475280761719\n",
            "10/284 --> Time elapsed 3.679647445678711\n",
            "20/284 --> Time elapsed 7.381670951843262\n",
            "30/284 --> Time elapsed 11.268615484237671\n",
            "40/284 --> Time elapsed 14.922036409378052\n",
            "50/284 --> Time elapsed 18.822232961654663\n",
            "60/284 --> Time elapsed 22.813828706741333\n",
            "70/284 --> Time elapsed 26.84990668296814\n",
            "80/284 --> Time elapsed 30.819823503494263\n",
            "90/284 --> Time elapsed 34.40035676956177\n",
            "100/284 --> Time elapsed 38.013901710510254\n",
            "110/284 --> Time elapsed 41.54912328720093\n",
            "120/284 --> Time elapsed 45.3312566280365\n",
            "130/284 --> Time elapsed 49.289283752441406\n",
            "140/284 --> Time elapsed 53.04489278793335\n",
            "150/284 --> Time elapsed 56.700992822647095\n",
            "160/284 --> Time elapsed 60.365641593933105\n",
            "170/284 --> Time elapsed 64.33445000648499\n",
            "180/284 --> Time elapsed 68.13032054901123\n",
            "190/284 --> Time elapsed 71.78282284736633\n",
            "200/284 --> Time elapsed 75.52945923805237\n",
            "210/284 --> Time elapsed 79.21090626716614\n",
            "220/284 --> Time elapsed 83.03287506103516\n",
            "230/284 --> Time elapsed 87.05604958534241\n",
            "240/284 --> Time elapsed 90.66930556297302\n",
            "250/284 --> Time elapsed 94.41555070877075\n",
            "260/284 --> Time elapsed 97.94777917861938\n",
            "270/284 --> Time elapsed 101.62713074684143\n",
            "280/284 --> Time elapsed 105.49811315536499\n",
            "Training took 106.89918565750122\n",
            "Accuracy: 0.8645833333333333, Time elapsed: 1.3247833251953125\n",
            "======== Epoch 16 / 20 ========\n",
            "0/284 --> Time elapsed 0.004810333251953125\n",
            "10/284 --> Time elapsed 3.9178333282470703\n",
            "20/284 --> Time elapsed 7.826514005661011\n",
            "30/284 --> Time elapsed 11.456232786178589\n",
            "40/284 --> Time elapsed 15.277387380599976\n",
            "50/284 --> Time elapsed 18.889387607574463\n",
            "60/284 --> Time elapsed 22.58049964904785\n",
            "70/284 --> Time elapsed 26.364398956298828\n",
            "80/284 --> Time elapsed 30.026281118392944\n",
            "90/284 --> Time elapsed 33.68216133117676\n",
            "100/284 --> Time elapsed 37.503937005996704\n",
            "110/284 --> Time elapsed 41.06557583808899\n",
            "120/284 --> Time elapsed 45.26060461997986\n",
            "130/284 --> Time elapsed 49.06342697143555\n",
            "140/284 --> Time elapsed 52.81309938430786\n",
            "150/284 --> Time elapsed 56.343366384506226\n",
            "160/284 --> Time elapsed 60.01590847969055\n",
            "170/284 --> Time elapsed 63.64898753166199\n",
            "180/284 --> Time elapsed 67.60832834243774\n",
            "190/284 --> Time elapsed 71.63071513175964\n",
            "200/284 --> Time elapsed 75.50611352920532\n",
            "210/284 --> Time elapsed 79.54233479499817\n",
            "220/284 --> Time elapsed 83.28063988685608\n",
            "230/284 --> Time elapsed 87.04616975784302\n",
            "240/284 --> Time elapsed 90.65645289421082\n",
            "250/284 --> Time elapsed 94.37310099601746\n",
            "260/284 --> Time elapsed 98.18945240974426\n",
            "270/284 --> Time elapsed 101.66290092468262\n",
            "280/284 --> Time elapsed 105.43766975402832\n",
            "Training took 106.79303193092346\n",
            "Accuracy: 0.8776960784313725, Time elapsed: 1.3238511085510254\n",
            "======== Epoch 17 / 20 ========\n",
            "0/284 --> Time elapsed 0.004595041275024414\n",
            "10/284 --> Time elapsed 3.695211410522461\n",
            "20/284 --> Time elapsed 7.17549204826355\n",
            "30/284 --> Time elapsed 11.248822212219238\n",
            "40/284 --> Time elapsed 14.957205772399902\n",
            "50/284 --> Time elapsed 18.488086223602295\n",
            "60/284 --> Time elapsed 22.27768611907959\n",
            "70/284 --> Time elapsed 26.00551724433899\n",
            "80/284 --> Time elapsed 29.618350982666016\n",
            "90/284 --> Time elapsed 33.50399112701416\n",
            "100/284 --> Time elapsed 37.36802315711975\n",
            "110/284 --> Time elapsed 41.08399796485901\n",
            "120/284 --> Time elapsed 44.76414942741394\n",
            "130/284 --> Time elapsed 48.20578193664551\n",
            "140/284 --> Time elapsed 52.27955865859985\n",
            "150/284 --> Time elapsed 56.3803231716156\n",
            "160/284 --> Time elapsed 60.39420962333679\n",
            "170/284 --> Time elapsed 64.06103610992432\n",
            "180/284 --> Time elapsed 67.97997879981995\n",
            "190/284 --> Time elapsed 71.76496362686157\n",
            "200/284 --> Time elapsed 75.5404269695282\n",
            "210/284 --> Time elapsed 79.23812961578369\n",
            "220/284 --> Time elapsed 82.93675255775452\n",
            "230/284 --> Time elapsed 86.46388268470764\n",
            "240/284 --> Time elapsed 90.42961430549622\n",
            "250/284 --> Time elapsed 94.17524147033691\n",
            "260/284 --> Time elapsed 97.96306467056274\n",
            "270/284 --> Time elapsed 101.6543562412262\n",
            "280/284 --> Time elapsed 105.26469802856445\n",
            "Training took 106.74582409858704\n",
            "Accuracy: 0.8740196078431373, Time elapsed: 1.328948736190796\n",
            "======== Epoch 18 / 20 ========\n",
            "0/284 --> Time elapsed 0.0053288936614990234\n",
            "10/284 --> Time elapsed 3.7181427478790283\n",
            "20/284 --> Time elapsed 7.375241279602051\n",
            "30/284 --> Time elapsed 11.006972312927246\n",
            "40/284 --> Time elapsed 14.849474906921387\n",
            "50/284 --> Time elapsed 18.449474811553955\n",
            "60/284 --> Time elapsed 22.157822132110596\n",
            "70/284 --> Time elapsed 26.155131340026855\n",
            "80/284 --> Time elapsed 29.980556964874268\n",
            "90/284 --> Time elapsed 33.82459330558777\n",
            "100/284 --> Time elapsed 37.69558548927307\n",
            "110/284 --> Time elapsed 41.498592376708984\n",
            "120/284 --> Time elapsed 45.10390639305115\n",
            "130/284 --> Time elapsed 48.892627000808716\n",
            "140/284 --> Time elapsed 52.817612171173096\n",
            "150/284 --> Time elapsed 56.61649417877197\n",
            "160/284 --> Time elapsed 60.10314655303955\n",
            "170/284 --> Time elapsed 64.09210896492004\n",
            "180/284 --> Time elapsed 68.0227484703064\n",
            "190/284 --> Time elapsed 71.77478694915771\n",
            "200/284 --> Time elapsed 75.55211877822876\n",
            "210/284 --> Time elapsed 79.44643092155457\n",
            "220/284 --> Time elapsed 83.386483669281\n",
            "230/284 --> Time elapsed 87.19254851341248\n",
            "240/284 --> Time elapsed 90.81975102424622\n",
            "250/284 --> Time elapsed 94.76553583145142\n",
            "260/284 --> Time elapsed 98.45762538909912\n",
            "270/284 --> Time elapsed 101.92448449134827\n",
            "280/284 --> Time elapsed 105.82732367515564\n",
            "Training took 107.06931328773499\n",
            "Accuracy: 0.8721813725490195, Time elapsed: 1.3252880573272705\n",
            "======== Epoch 19 / 20 ========\n",
            "0/284 --> Time elapsed 0.003849506378173828\n",
            "10/284 --> Time elapsed 3.5500454902648926\n",
            "20/284 --> Time elapsed 7.15728235244751\n",
            "30/284 --> Time elapsed 11.18637466430664\n",
            "40/284 --> Time elapsed 15.008225679397583\n",
            "50/284 --> Time elapsed 18.67807364463806\n",
            "60/284 --> Time elapsed 22.36754870414734\n",
            "70/284 --> Time elapsed 26.325150966644287\n",
            "80/284 --> Time elapsed 30.024682998657227\n",
            "90/284 --> Time elapsed 33.627575159072876\n",
            "100/284 --> Time elapsed 37.29455757141113\n",
            "110/284 --> Time elapsed 41.16350698471069\n",
            "120/284 --> Time elapsed 45.05884504318237\n",
            "130/284 --> Time elapsed 48.87739038467407\n",
            "140/284 --> Time elapsed 52.79527497291565\n",
            "150/284 --> Time elapsed 56.5101261138916\n",
            "160/284 --> Time elapsed 60.30612564086914\n",
            "170/284 --> Time elapsed 63.98754811286926\n",
            "180/284 --> Time elapsed 67.88564991950989\n",
            "190/284 --> Time elapsed 71.43802285194397\n",
            "200/284 --> Time elapsed 75.28785872459412\n",
            "210/284 --> Time elapsed 79.11980032920837\n",
            "220/284 --> Time elapsed 82.76716351509094\n",
            "230/284 --> Time elapsed 86.57457137107849\n",
            "240/284 --> Time elapsed 90.18235063552856\n",
            "250/284 --> Time elapsed 93.95714926719666\n",
            "260/284 --> Time elapsed 97.63576698303223\n",
            "270/284 --> Time elapsed 101.42708778381348\n",
            "280/284 --> Time elapsed 105.35790872573853\n",
            "Training took 106.72703146934509\n",
            "Accuracy: 0.8737745098039216, Time elapsed: 1.3234171867370605\n",
            "======== Epoch 20 / 20 ========\n",
            "0/284 --> Time elapsed 0.004870891571044922\n",
            "10/284 --> Time elapsed 3.451470136642456\n",
            "20/284 --> Time elapsed 7.327432632446289\n",
            "30/284 --> Time elapsed 10.968830347061157\n",
            "40/284 --> Time elapsed 14.772446155548096\n",
            "50/284 --> Time elapsed 18.368127584457397\n",
            "60/284 --> Time elapsed 22.007344484329224\n",
            "70/284 --> Time elapsed 25.628830432891846\n",
            "80/284 --> Time elapsed 29.09865927696228\n",
            "90/284 --> Time elapsed 32.898585081100464\n",
            "100/284 --> Time elapsed 36.859710693359375\n",
            "110/284 --> Time elapsed 40.49218487739563\n",
            "120/284 --> Time elapsed 44.250256299972534\n",
            "130/284 --> Time elapsed 47.94621300697327\n",
            "140/284 --> Time elapsed 51.902509927749634\n",
            "150/284 --> Time elapsed 55.820446491241455\n",
            "160/284 --> Time elapsed 59.411741495132446\n",
            "170/284 --> Time elapsed 63.05344772338867\n",
            "180/284 --> Time elapsed 66.77748918533325\n",
            "190/284 --> Time elapsed 70.71212577819824\n",
            "200/284 --> Time elapsed 74.47792506217957\n",
            "210/284 --> Time elapsed 78.25050377845764\n",
            "220/284 --> Time elapsed 81.86532187461853\n",
            "230/284 --> Time elapsed 85.84896183013916\n",
            "240/284 --> Time elapsed 90.00268745422363\n",
            "250/284 --> Time elapsed 93.8726897239685\n",
            "260/284 --> Time elapsed 97.27403402328491\n",
            "270/284 --> Time elapsed 101.0423994064331\n",
            "280/284 --> Time elapsed 104.83244705200195\n",
            "Training took 106.04977583885193\n",
            "Accuracy: 0.8742647058823529, Time elapsed: 1.3228654861450195\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbUm-D33qtpT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "0e3d123f-2209-4bf6-ec46-1c6517696fd1"
      },
      "source": [
        "# plot losses\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns \n",
        "\n",
        "plt.plot(losses, 'b-o')\n",
        "plt.title(\"Train Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0T8enD6pV_Qb"
      },
      "source": [
        "# torch.cuda.memory_summary(device=None, abbreviated=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_7uGtvzWpUr"
      },
      "source": [
        "import os \n",
        "\n",
        "output_dir = './model_save'\n",
        "\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "model_to_save = model.module if hasattr(model, 'module') else model\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "# tokenizer.save_pretrained(output_dir)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxTlo72cTanv"
      },
      "source": [
        "def run_test(df_test):\n",
        "\n",
        "    test_batch_size = 16\n",
        "\n",
        "    test_encoded_sentences, test_labels = preprocessing(df_test)\n",
        "\n",
        "    test_dataset = GrammerDataset( test_encoded_sentences , test_labels, max_sent_length)\n",
        "    test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
        "                                              batch_size= test_batch_size  ,\n",
        "                                              collate_fn=train_dataset.spam_collate_func,\n",
        "                                              shuffle=False)\n",
        "    sentences = df_test.sentence.values\n",
        "\n",
        "    model.eval()\n",
        "    eval_loss, eval_acc = 0,0\n",
        "\n",
        "    for step, batch in enumerate(test_loader):\n",
        "\n",
        "        sentence_batch = sentences[  step*test_batch_size  : (step + 1)*test_batch_size ]\n",
        "\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        eval_data, eval_masks, eval_labels = batch\n",
        "        with torch.no_grad():\n",
        "            out = model(eval_data,\n",
        "                        token_type_ids = None,\n",
        "                        attention_mask=eval_masks)\n",
        "        logits = out[0]\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        eval_labels = eval_labels.to('cpu').numpy()\n",
        "        batch_acc = compute_accuracy(logits, eval_labels)\n",
        "        eval_acc += batch_acc\n",
        "\n",
        "        preds = np.argmax( logits , axis=1).flatten()\n",
        "\n",
        "        for i_index in range( len(preds) ):\n",
        "\n",
        "          i_sentence = sentence_batch[i_index]\n",
        "          i_target = eval_labels[ i_index ]\n",
        "          i_pred = preds[ i_index ]\n",
        "\n",
        "          print( \"Sentence : {}  Target Label : {}  Prediction Label : {}  \\n\".format(  i_sentence , i_target , i_pred  ) )\n",
        "        \n",
        "        print(\"# of sentences: \", len(preds))\n",
        "\n",
        "    print(f\"Final Mode Accuracy: {eval_acc/(step+1)}\")"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CprT2x6YWDzc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ead7550d-8ec7-4a02-9041-002d06f5f26a"
      },
      "source": [
        "print(\"Evaluating on english \\n\")\n",
        "df_test = pd.read_csv(\"/content/in_domain_dev.tsv\", \n",
        "                 delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
        "run_test(df_test)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluating on english \n",
            "\n",
            "Sentence : The sailors rode the breeze clear of the rocks.  Target Label : 1  Prediction Label : 0  \n",
            "\n",
            "Sentence : The weights made the rope stretch over the pulley.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : The mechanical doll wriggled itself loose.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : If you had eaten more, you would want less.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : As you eat the most, you want the least.  Target Label : 0  Prediction Label : 1  \n",
            "\n",
            "Sentence : The more you would want, the less you would eat.  Target Label : 0  Prediction Label : 1  \n",
            "\n",
            "Sentence : I demand that the more John eat, the more he pays.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : Mary listens to the Grateful Dead, she gets depressed.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : The angrier Mary got, the more she looked at pictures.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : The higher the stakes, the lower his expectations are.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : The more Fred is obnoxious, the less attention you should pay to him.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : John was lots more obnoxious than Fred.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : The more people you give beer to, the more people get sick.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : The more does Bill smoke, the more Susan hates him.  Target Label : 0  Prediction Label : 1  \n",
            "\n",
            "Sentence : The more pictures of him that appear in the news, the more embarrassed John becomes.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Every senator seems to become more corrupt, as he talks to more lobbyists.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "# of sentences:  16\n",
            "Sentence : Who does John visit Sally because he likes?  Target Label : 0  Prediction Label : 1  \n",
            "\n",
            "Sentence : Marianne did not leave.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : He could not have been working.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : He can not have been working.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : You will believe Bob.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : John has not kissed Mary.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : I said that never in my life had I seen a place like Bangor.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Mickey looked up it.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : There tended to be a lot of discussion.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : John tried to be a good boy.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : John is eager.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : We want John to win.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : The box contained the ball from the tree.  Target Label : 0  Prediction Label : 1  \n",
            "\n",
            "Sentence : The tube was escaped by gas.  Target Label : 0  Prediction Label : 1  \n",
            "\n",
            "Sentence : Water bubbled up out of the kettle.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : The tub leaked water.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "# of sentences:  16\n",
            "Sentence : What the water did to the bottle was fill it.  Target Label : 0  Prediction Label : 1  \n",
            "\n",
            "Sentence : What the water did to the whole bottle was fill it.  Target Label : 0  Prediction Label : 1  \n",
            "\n",
            "Sentence : The tank leaked the fluid free.  Target Label : 1  Prediction Label : 0  \n",
            "\n",
            "Sentence : John lay the ball in the box.  Target Label : 1  Prediction Label : 0  \n",
            "\n",
            "Sentence : John owns the book.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : We persuaded Mary to leave and Sue to stay.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Most people probably consider, even though the courts didn't actually find, Klaus guilty of murder.  Target Label : 1  Prediction Label : 0  \n",
            "\n",
            "Sentence : Mary beautifully plays the violin.  Target Label : 0  Prediction Label : 1  \n",
            "\n",
            "Sentence : Clearly, John probably will immediately learn French perfectly.  Target Label : 1  Prediction Label : 0  \n",
            "\n",
            "Sentence : Sue gave to Bill a book.  Target Label : 0  Prediction Label : 1  \n",
            "\n",
            "Sentence : The men will all leave.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : John went home.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : They represented seriously to the dean Mary as a genuine linguist.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : Us love they.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : It is nice to go abroad.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Mary intended John to go abroad.  Target Label : 0  Prediction Label : 1  \n",
            "\n",
            "# of sentences:  16\n",
            "Sentence : I remembered having kissed Mary.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : I can't believe Fred won't, either.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : John wants to read Fred's story, and I also want to.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : We wanted to invite someone, but we couldn't decide who to.  Target Label : 0  Prediction Label : 1  \n",
            "\n",
            "Sentence : Mary will read Fred's story, and Joe will read Holly's.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Mary claimed that eating cabbage, Holly shouldn't.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Mary came to be introduced by the bartender and I also came to be.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : If I can, I will work on it.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Joe's neuroses bother his patrons, and Sally does too.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : I know which book José didn't read for class, and which book Lilly did it for him.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : This is the book which Bob reviewed, and this is the one which Fred won't do it.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : I know which book Mag read, and which book Bob said that you hadn't.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : I know which book Mag read, and which book Bob read my report that you hadn't.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : I'm sure I would like him to eat fruit more than I would cookies.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Rusty talked about himself only after Mary did talk about him.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Fred talked about everything before Rusty did talk about something.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "# of sentences:  16\n",
            "Sentence : John often meets Mary.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : The problem perceives easily.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : A hundred men surrounded the fort.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : We elected me.  Target Label : 1  Prediction Label : 0  \n",
            "\n",
            "Sentence : Which report that John was incompetent did he submit?  Target Label : 0  Prediction Label : 1  \n",
            "\n",
            "Sentence : Mary has always preferred lemons to limes.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : He let the cats which were whining out.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : What did Bill buy?  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Mary saw the boy walking toward the railroad station.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : A proof that the claim had been made was given that John had lied.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : He attributed to a short circuit which was caused by an overloaded transducer the fire which destroyed most of my factory.  Target Label : 1  Prediction Label : 0  \n",
            "\n",
            "Sentence : The mayor regarded as being absurd the proposal to build a sidewalk from Dartmouth to Smith.  Target Label : 0  Prediction Label : 1  \n",
            "\n",
            "Sentence : I want that Bill left to remain a secret.  Target Label : 0  Prediction Label : 1  \n",
            "\n",
            "Sentence : I know a man who Tom drives as drives.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : Drowning cats, which is against the law, are hard to rescue.  Target Label : 0  Prediction Label : 1  \n",
            "\n",
            "Sentence : Muriel said nothing else than that she had been insulted.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "# of sentences:  16\n",
            "Sentence : Himself is understood by Rutherford.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : I feel that Arch will show up.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : The proof this set is recursive is difficult.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : The madrigals which Henry plays the lute and sings sound lousy.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : Tom picked these grapes, and I washed some turnips, and Suzie will prepare these grapes.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Where did you go and who ate what?  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Which boy's did we elect guardian's employer president?  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : How sane is Peter?  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : I live at the place where Route 150 crosses the River and my dad lives at the place where Route 150 crosses the Hudson River too.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : I live at the place where Route 150 crosses the Hudson River and my dad lives at it too.  Target Label : 0  Prediction Label : 1  \n",
            "\n",
            "Sentence : Who is she trying to make up to now?  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Wind was gotten of a plot to negotiate an honorable end to the war in Vietnam.  Target Label : 0  Prediction Label : 1  \n",
            "\n",
            "Sentence : Mike talked about politics yesterday to my friends.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : It was expected by the reporters that the principal would fire some teacher.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Which hat did Mike quip that she never wore?  Target Label : 0  Prediction Label : 1  \n",
            "\n",
            "Sentence : Which girl did Mike quip never wore this hat?  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "# of sentences:  16\n",
            "Sentence : We donated wire for the convicts to build cages with.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : I won't have some money.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : Do you believe the claim that somebody was looking for something?  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : I won't ask you to believe that he tried to force me to give her any money.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : That Sam sometimes didn't sleep must have pleased somebody.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : I talked to Winston about himself.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : That the fuzz wanted him worried John, but that the fuzz wanted her didn't worry Mary.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : I'll work on it if Sam will be working on it.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : I'll work on it if I can.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Here's a knife with which for you to cut up the onions.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : Fluffy is sick, which not everybody knows.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Maxwell is quite a doctor.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : The younger woman might have been tall and, and the older one definitely was, blond.  Target Label : 0  Prediction Label : 1  \n",
            "\n",
            "Sentence : Sally is tall, and may be blond, and Sheila is short, and definitely is, blond.  Target Label : 1  Prediction Label : 0  \n",
            "\n",
            "Sentence : I have to try to finish grading some papers.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : The socks are ready for for you to put on to be planned.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "# of sentences:  16\n",
            "Sentence : It is easy to play sonatas on this violin.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : This violin is difficult to play sonatas on.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : My mother is easy to please my father and.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : Poor Bill, it had started to rain and he had no umbrella.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : That the cops spoke to the janitor about it yesterday is terrible, that robbery.  Target Label : 0  Prediction Label : 1  \n",
            "\n",
            "Sentence : Every student, and he wears socks, is a swinger.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : That girl was given my binoculars by him.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Bill didn't allege that Roger had eaten anything.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Nobody who hates to eat anything should work in a delicatessen.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Everybody around here who ever buys anything on credit talks in his sleep.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : I can't remember the name of somebody who had misgivings.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : No writer, and no playwright, meets in Vienna.  Target Label : 0  Prediction Label : 1  \n",
            "\n",
            "Sentence : No writer, nor any playwright, meets in Vienna.  Target Label : 0  Prediction Label : 1  \n",
            "\n",
            "Sentence : That you will marry any student is not certain.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Felicia kicked the ball off the bench.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : I sent the package halfway around the world.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "# of sentences:  16\n",
            "Sentence : Sam gave the ball out of the basket.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : Sam offered the ball out of the basket.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : Park Square has a festive air.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : The worker will have a job.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : No one can forgive that comment to you.  Target Label : 0  Prediction Label : 1  \n",
            "\n",
            "Sentence : We launched the rocket to the moon, but it blew up before it got there.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Sarah promised Catherine her old car, but then gave it to her son instead.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : I lent the book partway to Tony.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : The farmer loaded the cart with apples.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : The farmer dumped the cart with apples.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : Martha carved the baby a toy out of wood.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : The bread cuts easily.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Janet broke Bill on the finger.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : Janet broke the cup.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : The visitor rang the bell.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : We pulled free.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "# of sentences:  16\n",
            "Sentence : That movie always shocks people.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : That movie always shocks.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Sharon came the room.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : Bill sent a package to Tom.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : That acorn will grow into an oak tree.  Target Label : 1  Prediction Label : 0  \n",
            "\n",
            "Sentence : He turned into a frog.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : I mixed the sugar into the butter.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Brian threw the fence with the stick.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : Mira condemned Terry for the accident.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : We investigated the area for bombs.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : I sensed his eagerness.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : They praised the dedication in the volunteers.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : The earth was believed to be round.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Sarah smiled a charming smile.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Sandra beamed a cheerful welcome.  Target Label : 1  Prediction Label : 0  \n",
            "\n",
            "Sentence : You've really lived it up.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "# of sentences:  16\n",
            "Sentence : Paperback books lift onto the table easily.  Target Label : 0  Prediction Label : 1  \n",
            "\n",
            "Sentence : The books lifted onto the table.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : Jessica loaded boxes under the wagon.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Jessica loaded boxes on the wagon.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Jessica crammed boxes at the truck.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : Lora buttered at the toast.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : Carla shoveled the walk.  Target Label : 1  Prediction Label : 0  \n",
            "\n",
            "Sentence : Nora sent the book.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Nora sent Peter the book.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Carla slid the book.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Carla slid at the book.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : Amanda carried the package to Pamela.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Packages drive easily to New York.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : The chair pushed.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : We offered a job to her.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : A job offered.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "# of sentences:  16\n",
            "Sentence : Brown presented a plaque to Jones.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Carmen bought Mary a dress.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Carmen obtained the spare part at the hardware store.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Michelle kept the desk with the papers.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : Frances hid the presents in the drawer.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : The needle poked the cloth.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Carrie touched that cat.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Herman whipped the sugar and the cream.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : Linda taped the picture to the wall.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Linda taped the picture onto the wall.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : The child and her mother clung together.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : This flyer and that flyer differ.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : This flyer and that flyer differ apart.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : The jeweller scribbled the contract with his name.  Target Label : 0  Prediction Label : 1  \n",
            "\n",
            "Sentence : The gardener grew that acorn into an oak tree.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : I shaped a loaf.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "# of sentences:  16\n",
            "Sentence : The children amused.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : Susan whispered the news.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Susan whispered at Rachel.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Ellen said that melons were selling well.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Ellen said about the present conditions.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : Ellen warned Helen against skating on thin ice.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Cynthia nibbled on the carrot .  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Cynthia chewed.  Target Label : 0  Prediction Label : 1  \n",
            "\n",
            "Sentence : Paul laughed at Mary.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Linda winked her lip.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : My heart is pounding me.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : Sharon fainted from hunger.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : The witch poisoned the children.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : A grandfather clock ticked in the hallway.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : I squeaked the door.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : Over the fire there bubbled a fragrant stew.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "# of sentences:  16\n",
            "Sentence : Soaring temperatures are predicted for this weekend.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : The fort fluttered with many flags.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : The voices echoed in the hall.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : The stream twists through the valley.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : There presented itself a wonderful opportunity yesterday.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : A wonderful opportunity presented itself to him yesterday.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Out of the box jumped a little white rabbit.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Penny skated around the rink.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Jackie accompanied Rose.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : many information was provided.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : John offers many advice.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : The cake that Jones got was more delicious than the one that Smith got.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : We recommend to eat less cake and pastry.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : I saw that gas can explode.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : He washed her.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Wash you!  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "# of sentences:  16\n",
            "Sentence : They have no in.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : Some my jobs are in jeopardy.  Target Label : 0  Prediction Label : 1  \n",
            "\n",
            "Sentence : It was the policeman met that several young students in the park last night.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : did the policeman meet in the park?  Target Label : 1  Prediction Label : 0  \n",
            "\n",
            "Sentence : John put old books in the box.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : The monkeys proud of their leader.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : John sounded very.  Target Label : 0  Prediction Label : 1  \n",
            "\n",
            "Sentence : I don't know if I should agree.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : John bought a book on the table.  Target Label : 1  Prediction Label : 0  \n",
            "\n",
            "Sentence : John called the president a fool.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : I forgot how good beer tastes.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : This teacher is a genius.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : A good friend is remained to me by him.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : John ate his noodle quietly.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : A smith hammered the metal.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Sandy removed her ballet shoes.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "# of sentences:  16\n",
            "Sentence : This week will be a difficult one for us.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Benny worked in a shoe factory when he was a student.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Everyone hoped that she would sing.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : This proved a decisive factor.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : The crocodile devoured the doughnut.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : John is afraid of Bill.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : John put under the bathtub.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : John placed Kim behind the garage.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Kim depends for Sandy.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : John put the book in the box.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : John taught English Syntax to new students.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : John regards Bill as a good friend.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Kim put in the box.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : The chickens seem fond of the farmer.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : The rules require that the executives be polite.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : That Fred was unpopular nominated Bill.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "# of sentences:  16\n",
            "Sentence : They were taking a hard look at possible FTA.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : John paid me against the book.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : The committee will study the feasibility of setting up a national computer network.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : We made them be rude.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : After reading the pamphlet, Judy threw it into the garbage can.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Students studying English reads Conrad's Heart of Darkness while at university.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : I read some of the book.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Most of the fruit is rotten.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Neither of students failed.  Target Label : 0  Prediction Label : 1  \n",
            "\n",
            "Sentence : I drank some of water.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : It is a golden hair.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : The boy in the doorway waved to his father.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : That dog is so ferocious, it even tried to bite itself.  Target Label : 1  Prediction Label : 0  \n",
            "\n",
            "Sentence : He washed yourself.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : John is easy to please Kim.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : There seemed to be intelligent.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "# of sentences:  16\n",
            "Sentence : John tried to please Stephen.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : We believed John to be a fountain in the park.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : It tries to leave the country.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : John tries to leave the country.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Under the bed seems to be a fun place to hide.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : There is believed to be sheep in the park.  Target Label : 0  Prediction Label : 1  \n",
            "\n",
            "Sentence : I hope to would study in France.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : John can kick the ball.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : John will rain tomorrow.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : We expect there to will rain.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : John was found in the office.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Did the child be in the school?  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : It did not rain.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : John wants not to leave the town.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Mary likes to tour art galleries, but Bill hates to.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : They needn't take this exam.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "# of sentences:  16\n",
            "Sentence : Ann may spend her vacation in Italy.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : They love to play golf, but I do not.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : George has spent a lot of money, hasn't he?  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : As a statesman, scarcely could he do anything worth mentioning.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : We never found any of the unicorns.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : One of Korea's most famous poets wrote these lines.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Somebody apparently struck the unidentified victim during the early morning hours.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : The car was driven.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Ricky can be relied on.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : The bed was slept in.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : A pound was weighed by the book.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : Who do you think Tom saw?  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : he had spent five thousand dollars.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Fed knows which politician her to vote for.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : How did you guess that he fixed the computer?  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : The committee knows whose efforts to achieve peace the world should honor.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "# of sentences:  16\n",
            "Sentence : Which house does your friend live?  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : the baker from whom I bought these bagels left.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : I found the place where we can relax.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Jack is the person with whom Jenny fell in love with.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : There is a bench to sit on.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : I met the man who grows peaches.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Which topic did you choose without getting his approval?  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Which topic did you get bored because Mary talked about?  Target Label : 0  Prediction Label : 1  \n",
            "\n",
            "Sentence : That is the reason why he resigned.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : It bothers me that John coughs.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : To please John is easy.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Kim is eager to please Tom.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : That we invaded Iraq really bites.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : It annoys me that Fido barks.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Who achieved the best result was Angela.  Target Label : 0  Prediction Label : 1  \n",
            "\n",
            "Sentence : It was the peasant girl who got it.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "# of sentences:  16\n",
            "Sentence : That kind of person is hard to find anyone to look after.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : A sick owl doesn't hunt mice.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Each candidate who has interest in semantics will be admitted to the department.  Target Label : 1  Prediction Label : 0  \n",
            "\n",
            "Sentence : Each author whose contribution is written in any language other than English will provide a summary in English.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : I'm sure we even got these tickets!  Target Label : 1  Prediction Label : 0  \n",
            "\n",
            "Sentence : I'm even sure we got these tickets!  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : It's not because I have any sympathy for urban guerillas that I helped him.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : It isn't because Sue said anything bad about me that I'm angry.  Target Label : 1  Prediction Label : 0  \n",
            "\n",
            "Sentence : That he was hungry, John whined.  Target Label : 0  Prediction Label : 1  \n",
            "\n",
            "Sentence : I gave Mary after the party a book.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : Because she's so pleasant, as for Mary I really like her.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : Though he may hate those that criticize Carter, it doesn't matter.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : With no job would John be happy.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : I have much of the manuscript left to type.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : He's a more reliable man.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Any trouble is what I don't want.  Target Label : 0  Prediction Label : 1  \n",
            "\n",
            "# of sentences:  16\n",
            "Sentence : They may grow as high as bamboo.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Some of them made as many errors as 20.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Sally kissed himself.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : Drew believes I think Rosie loves magazine ads.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Dave, Dan, Erin, Jaime, and Alina left.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Hopefully, we'll make it through the winter without snow.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Blue leather shows herself that Betsy is pretty.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : Gwen hit the baseball.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : I hit that you knew the answer.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : I've lost my wallet or I've lost my mind.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : It was a brand new car that he bought.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : He likes cookies and he hates crumb cake.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : They chased the man with the car.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : I didn't have a red cent.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : the book of poems and from Blackwell takes a very long time to read.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : the one with a red cover takes a very long time to read.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "# of sentences:  16\n",
            "Sentence : John has a fear of dogs.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : The building's the roof is leaking.  Target Label : 0  Prediction Label : 1  \n",
            "\n",
            "Sentence : the panther's the coat is dark black.  Target Label : 0  Prediction Label : 1  \n",
            "\n",
            "Sentence : Colin asked if they could get a mortgage.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : The man I saw get into the cab robbed the bank.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : I know you eat asparagus.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : John's drum will always bother me.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : An evil thought struck Dave.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : In the classroom John put the book on the table.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Phillip gave the medal to the soldier.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Heidi thinks that Andy to eat salmon flavored candy bars.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : Heidi thinks that Andy should eat salmon flavored candy bars.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : He danced.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Did Calvin his homework?  Target Label : 0  Prediction Label : 1  \n",
            "\n",
            "Sentence : Sylvia was slapping Jeff upside the head in martial arts class.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : If I am a rich man, I'd buy a diamond ring.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "# of sentences:  16\n",
            "Sentence : If he were a rich man, he'd buy a diamond ring.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : John is likely to leave.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : The manager laughed.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Was sunk.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : Who did you think kissed the gorilla?  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Have you seen my model airplane collection?  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : It seems that Lucy was mugged.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : I ate a salad that was filled with lima beans.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : There were four men arriving at the station when I pulled up.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Jean is reluctant to dance.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : I want her to dance.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Jean persuaded Robert.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Jean wants Bill to do the Macarena.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : The children admire their mother.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Who has Peter talked with?  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Heidi likes her violin.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "# of sentences:  16\n",
            "Sentence : John thinks that Mary loves himself.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : Which pictures of himself does John like?  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Any owl hunts mice.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Any man didn't eat dinner.  Target Label : 0  Prediction Label : 1  \n",
            "\n",
            "Sentence : A pilot could be flying this plane.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Everybody who attended last week's huge rally, whoever they were, signed the petition.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Anybody who attended last week's huge rally signed the petition.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Any tiger has orange fur, marked with black stripes.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Any albino tiger has orange fur, marked with black stripes.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : You must pick any flower you see.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Any pilot on duty today could be flying this plane.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : You may pick every flower, but leave a few for Mary.  Target Label : 0  Prediction Label : 1  \n",
            "\n",
            "Sentence : The Dodgers beat the Red Sox and were beaten by the Giants.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : In which car was the man seen?  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : The man who Mary loves and Sally hates computed my tax.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : The kennel which Mary made and Fido sleeps has been stolen.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "# of sentences:  16\n",
            "Sentence : Tom said he would and Bill actually did eat a raw eggplant.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : The wealthy young man bought that piano for his secret fiancée.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : The dog stole the turkey.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : a tall building.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : This building is tall.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : I like the book which you gave me.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Captain Wentworth wrote a letter to Anne Elliott.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : She asked was Alison coming to the party.  Target Label : 1  Prediction Label : 0  \n",
            "\n",
            "Sentence : They realised that never had Sir Thomas been so offended.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Fanny regretted having to talk to Aunt Norris.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Knowing the country well, he took a short cut.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : He left the train with somebody else's wallet in his pocket.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Magnus went to Ireland.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Who did John send the book?  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : The idea dismayed the Prime Minister that the Dome was dull.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Came right in he did without so much as a knock.  Target Label : 1  Prediction Label : 0  \n",
            "\n",
            "# of sentences:  16\n",
            "Sentence : Harriet admired Mr Knightley.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : The book is boring.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Ethel wishes to ask you some awkward questions.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Emma made Harriet some food.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : The window was broken with a hammer.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : The fugitive lay motionless in order to avoid discovery.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : The guard marched the prisoners round the yard.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Frank Churchill crossed the street.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Emma and Harriet were attacked yesterday.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Fiona might be here by 5 o'clock.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : I am both expecting to get the job and of the opinion that it is a desirable one.  Target Label : 1  Prediction Label : 0  \n",
            "\n",
            "Sentence : Pat was awarded the Golden Fleece Award and very upset about it.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Kim alienated cats and beating his dog.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : They knew that pictures of each other would be on sale.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Which article did Terry file papers without reading?  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : I want to try and buy some whiskey.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "# of sentences:  16\n",
            "Sentence : She goes and buying some whiskey.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : Kim and Terry is happy.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : Kim gave a dollar to Bobbie and a dime to Jean.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : This girl in the red coat will put a picture of Bill in the mailbox and on your desk before tomorrow.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Put a picture of Bill on your desk before tomorrow, this girl in the red coat will put a picture of Bill on your desk before tomorrow.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : Picture of Bill, this girl in the red coat will put a picture of Bill on your desk before tomorrow.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : Ann bought a first edition of Richard III for $1000.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : John became deadly afraid of flying.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : What John promised is to be gentle.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Henri wants to buy which books about cooking?  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : I will fix the computer for Carol.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Smith loaned a valuable collection of manuscripts to the library.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : The paper is cut by Mary.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : It was from six to nine or it took place from six to nine.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Suddenly, there arrived two inspectors from the INS.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : The soup cooks, thickens.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "# of sentences:  16\n",
            "Sentence : I gave money to the charity.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : John asked.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : I saw even the student.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : John whispered Mary left.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : Mary wonders that Bill will come.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : Sophie will theater.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : John finished the cake and drank the lemonade.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Herself likes Mary's mother.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : Each of the boys fought with some of the other boys.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : John's mother likes himself.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : Mary revealed himself to John.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : Mary believes that Bill saw himself.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : John heard that they criticized themselves.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : Mary thinks that she is smart.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Henry found that Bill is sad.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : John considers himself proud of Mary.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "# of sentences:  16\n",
            "Sentence : You should sit before there.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : There is a nurse available.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Everyone hopes everyone to sleep.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : Everyone hopes that he will sleep.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Only Churchill remembered Churchill giving the Blood, Sweat and Tears speech.  Target Label : 0  Prediction Label : 1  \n",
            "\n",
            "Sentence : John promise Mary to shave himself.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : John convinced Bill that Mary should sleep.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : I saw Bill while you did so Mary.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : What Mary did Bill was give a book.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : The bears sniffed  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : to steal talismans from witches is dangerous  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Anson demonized  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : You kicked yourselves  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : The book that I said that I'd never read.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Anson demonized up the Khyber  Target Label : 0  Prediction Label : 1  \n",
            "\n",
            "Sentence : It is not true that I might be going to the party.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "# of sentences:  16\n",
            "Sentence : Kick you!  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : Jason persuaded the doctor to treat Medea  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Who did you get an accurate description of?  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : The Peter we all like was at the party  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : The government's imposition of a fine.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Did Athena help us?  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : You wanted to meet the man I saw.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Anson demonized David every day  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : There is a programme about Euripides on a Radio 4 tonight?  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Medea denied poisoning the phoenix.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : The elixir was hidden in a hole in the ground  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Extremely frantically, Anson danced at Trade  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : What did you ask who Medea gave?  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : It's Anson that I like  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Medea tried the nurse to poison her children.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : I felt that I know you.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "# of sentences:  16\n",
            "Sentence : Will he can do it?  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : I ate that she was happy  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : Anson believed himself to be handsome.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : We arrived about six o'clock  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Gilgamesh is having fought the dragon.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : Anson thought that himself was happy.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : Fortunately Hermione passed biology  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : I might be not going to the party but washing my hair  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : I thought he liked myself  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : The butler sent the poison to Dinah.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Jason happens to appear to seem to be sick.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : What did you ask who saw?  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : We linguists love to argue  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : He can will go  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : How fierce the battle?  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : Which king did you ask which city invaded?  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "# of sentences:  16\n",
            "Sentence : It is some disgruntled old pigs in those ditches that humans love to eat.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : That banana is eating the monkey.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Burn them!  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : It stinks that Aphrodite is omnipotent.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Agamemnon seems to be a maniac  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Will Anson come to the party?  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : I wondered who Medea had poisoned.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : I inquired when could we leave.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : They kicked them  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : The monkey is ate the banana  Target Label : 0  Prediction Label : 1  \n",
            "\n",
            "Sentence : I would like to could swim  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : I kicked myself  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : The bookcase ran  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : I shaved myself.  Target Label : 1  Prediction Label : 0  \n",
            "\n",
            "Sentence : Anson became a muscle bound.  Target Label : 0  Prediction Label : 1  \n",
            "\n",
            "# of sentences:  15\n",
            "Final Mode Accuracy: 0.8765151515151516\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pR4gEedrFZbI",
        "outputId": "a804755e-1440-42e2-9780-3d995a2e2e45"
      },
      "source": [
        "print(\"Evaluating on french \\n\")\n",
        "df_test = pd.read_csv(\"/content/french_data.csv\", header=None, names=['label', 'sentence'] , skiprows=1)\n",
        "run_test(df_test)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluating on french \n",
            "\n",
            "Sentence : Emma mange une pomme.   Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : J'ai visité la Tour Eiffel le dimanche dernier.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Le livre a été lu par ma sœur.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Il ne faut pas faire des bêtises.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Maman ma dit de ne pas regarder trop de télévision.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Mon ami Pierre aime les tomates, mais il n'aime pas les avocats.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Je voudrais aller au Japon pendants les vacances.   Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Sais-tu où est mon chien?   Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Élise ma raconté qu'elle avait passé ses vacances en Cannes.   Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Henri ne sais pas pourquoi sa copine est en colère.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Comment vas-tu?  Target Label : 1  Prediction Label : 0  \n",
            "\n",
            "Sentence : Je vais bien, mais je suis un peu fatigué.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Sam a peur.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Je ne veus pas manger ce fromage.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Thomas a oublié d'acheter du jus d'orange quand il a fait les courses.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Adelina a un problème, elle ne sait pas nager.   Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "# of sentences:  16\n",
            "Sentence : Est-ce que je peux avoir de la pomme purée s'il vous plaît.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Je t'aime ma chérie.   Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Je pensais que c'était fini.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Qui est Alice?   Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Vous allez devoir apprendre.   Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Je conduis la voiture.   Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Justine conduit la voiture jusqu'a Paris.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Je vais mieux, merci.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Tu as de la chance.  Target Label : 1  Prediction Label : 0  \n",
            "\n",
            "Sentence : Qu'est-ce qu tu manges?  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Je ne peux pas t'entendre.   Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Alice était bizarre hier.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Il est trop fort.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Cette histoire n'est pas très amusante.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Liu était le meilleur élève de ma classe.   Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Les galettes des rois ce mangent en janvier.   Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "# of sentences:  16\n",
            "Sentence : Je te verrai dans une heure.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Quand j'avais dix ans, j'habitais au Japon.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Je n'ai pas besoin de ton aide.   Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : François m'a parlé du livre qu'il a emprunté à son père.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Peux-tu dire à ton frére de m'envoyer un message.   Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Pourquoi ne t'es-tu pas défendu?  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Ce n'est pas ta faute.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Il fait froid mais le soleil brille donc nous sortons nous promener.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : C'est la meilleure tarte qu'il ai jamais mangée.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : J'ai sauté du train avant qu'il ne soit arrêté et je me suis cassé le bras.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Ne me dérangez pas pendant que je travaille.   Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : L'arbre sous lequel nous jouons est haut.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Si j'étais magicien, je changerais le monde.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Je n'ais pas aimé cette photo de moi.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Je me demande à qui nous pouvons faire confiance.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Adrien a mangé les biscuits et Guillaume a mangé les chocolats.  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "# of sentences:  16\n",
            "Sentence : Cyrille m'a parlé de vous.   Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : Emma mange orange une.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : J'ai visité la Tour Eiffel le dmanche dernier.  Target Label : 0  Prediction Label : 1  \n",
            "\n",
            "Sentence : Le livre a été lu par mon sœur.  Target Label : 0  Prediction Label : 1  \n",
            "\n",
            "Sentence : Maman ma dit de pas regarder trop de télévision.  Target Label : 0  Prediction Label : 1  \n",
            "\n",
            "Sentence : N'hésitez pas me à poser des questions.  Target Label : 0  Prediction Label : 1  \n",
            "\n",
            "Sentence : J'aime aller au cinema ave mon amis  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : Qu'est-ce que tu es dans la main?  Target Label : 0  Prediction Label : 1  \n",
            "\n",
            "Sentence : Je veux devenir bientôt demain médecin.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : Je n'ai pas mon livre hier.  Target Label : 0  Prediction Label : 1  \n",
            "\n",
            "Sentence : J'aimerais la recontrer hier.  Target Label : 0  Prediction Label : 1  \n",
            "\n",
            "Sentence : Est-ce que vous savoir parlez anglais?  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : Cette personne est comme un fils pour marcher Glynn.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : Jean m'a dit que c'était ta décision manger.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : Julian ont été très clair avec toi.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : Une grenouille sortit de l'eau hier aujourd’hui .  Target Label : 0  Prediction Label : 1  \n",
            "\n",
            "# of sentences:  16\n",
            "Sentence : Ces vêtements n'est même pas sales.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : Tu ne travailles même aujourd'hui.  Target Label : 0  Prediction Label : 1  \n",
            "\n",
            "Sentence : Il est relativement d'enseigner le français.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : Les écoles doivent également enseigner aux étudients à apprendre.  Target Label : 0  Prediction Label : 1  \n",
            "\n",
            "Sentence : J'observe les gens faire la les cuisine.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : Nous n'avons tout le temps d'être seuls.  Target Label : 0  Prediction Label : 1  \n",
            "\n",
            "Sentence : Justine conduit la voiture jusqu'aux Paris.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : Vous devoir allez apprendre .   Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : Cette histoire n'est pas amusante très.  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : Vous êtes les seuls à gagner pouvoir.  Target Label : 0  Prediction Label : 1  \n",
            "\n",
            "# of sentences:  10\n",
            "Final Mode Accuracy: 0.795\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5lyW_KnFa2a",
        "outputId": "602d430f-70b3-4e05-f309-d7d711653d4f"
      },
      "source": [
        "print(\"Evaluating on chinese \\n\")\n",
        "df_test = pd.read_csv(\"/content/chinese_data.csv\",  header=None, names=['label', 'sentence'] , skiprows= 1 )\n",
        "run_test(df_test)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluating on chinese \n",
            "\n",
            "Sentence : 年夜饭常常有鱼，但是在北部，人们也喜欢吃饺子。在南部，人们喜欢吃年糕。  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : 去年的黄金周，我跟我的朋友们一起去南京。我的最好的朋友让我参加旅行，因为我们有三天的周末。  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : 介绍一下云南省和云南省的几个旅游景点。  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : 这个城市吸引了很多人，特别是年轻的人，因为城市有教育和工作机会，外国客人和很多好玩的事情。  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : 要是你去上海，一定会看见到处都有建筑工人在修马路，大桥和高楼。  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : 我们的时间在南京很短，但是我想又去为了做很多活动。  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : 我没参加过旅游团，所以我不知道。  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : 我觉得秦朝给我留下的印象很深，因为秦始皇当中国第一皇帝。  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : 差不多4点30早上 我们去火车站。  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : 我们的课都完了以后，为了准备旅行，我们回宿舍。  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : 我爱你。  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : 我很累。  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : 今天我有一个考试。  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : 他不是我的朋友。  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : 我不认识他。  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : 我很高兴认识你。  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "# of sentences:  16\n",
            "Sentence : 新年快乐！  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : 我的头疼，我肚子也疼，恐怕我生病了。  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : 日本在中国的东边。  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : 上海是中国的城市。  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : 可以慢慢说的吗？  Target Label : 1  Prediction Label : 0  \n",
            "\n",
            "Sentence : 我看不懂。  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : 我不会说英文，只会说中文。  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : 我是个大学生。  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : 他有很多的粉丝，因为他是有名的偶像。  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : 我们的老师教他们这么理财。  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : 有没有孩子？  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : 你多大？  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : 找男女朋友的时候，你有什么标准？  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : 他非常喜欢旅行，今年他已经去过巴黎，纽约，北京，东京，伦敦，什么的。  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : 我想请你吃饭。  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : 学中文不是那么难，其实比较容易。  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "# of sentences:  16\n",
            "Sentence : 你的爱，你的笑， 给我无限动力。  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : 我要宠着你。  Target Label : 1  Prediction Label : 0  \n",
            "\n",
            "Sentence : 想打倒我?  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : 从不曾回头。  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : 我先睡觉了。  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : 你上午都做了什么？  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : 你的心在上海哦？  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : 今天你怎么样？  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : 我喜欢短头发的女孩。  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : 但是我的头发比较短哈哈要是我想很长的头发，就加头发。  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : 你看起来好迷人。  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : 你太客气了！  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : 我今天很好，你呢？  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : 我觉得你真的很美啊。  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : 现在我有点累，因为比较晚。  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : 你中文好棒啊。  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "# of sentences:  16\n",
            "Sentence : 我今天就正常的工作日。  Target Label : 1  Prediction Label : 0  \n",
            "\n",
            "Sentence : 你有没有一些计划？  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : 看你喜欢我如何称呼你。  Target Label : 1  Prediction Label : 0  \n",
            "\n",
            "Sentence : 在上海读书一年半，现在我的课都在上网。  Target Label : 1  Prediction Label : 0  \n",
            "\n",
            "Sentence : 你在上海上大学？  Target Label : 1  Prediction Label : 0  \n",
            "\n",
            "Sentence : 你什么时候来上海？  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : 我想交流语言和文化。  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : 你我皆凡人，孤独是常态。  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : 在喝点吗？  Target Label : 1  Prediction Label : 0  \n",
            "\n",
            "Sentence : 不管同学们怎样笑她，她一点也不感到慌乱。  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : 那些参观的人走了以后的事情，她用那已经开始在褪着色的青手捧着眼泪。  Target Label : 1  Prediction Label : 0  \n",
            "\n",
            "Sentence : 我也不和她并床。  Target Label : 1  Prediction Label : 1  \n",
            "\n",
            "Sentence : 不我知道。  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : 认识我她。  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : 把我杯子桌子上。  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : 时候什么点 。  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "# of sentences:  16\n",
            "Sentence : 被功课 是他的狗，所以他没做完。  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : 椅子上有一个人。  Target Label : 0  Prediction Label : 1  \n",
            "\n",
            "Sentence : 他我爱。  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : 我一年半主在了。  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : 天气小星期吗吗。  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : 热我上说对不起。  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : 今天菜写吗杯子。  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : 多少米饭对不起做怎么？  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : 朋友都说冷不客气。  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : 电影人学校去今天。  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : 北京怎么样她他喜欢。  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : 再见几漂亮小电影。  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : 在四看见猫杯子。  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : 猫什么名字谁给它吗。  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : 四点来这买？  Target Label : 0  Prediction Label : 1  \n",
            "\n",
            "Sentence : 爸爸年小姐同学爸爸。  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "# of sentences:  16\n",
            "Sentence : 些看多少谁很。  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : 请坐同学少跟。  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : 想工作请一点儿工作  Target Label : 0  Prediction Label : 1  \n",
            "\n",
            "Sentence : 五 次我们写呢他！  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : 号怎么样前面家?  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "Sentence : 她喜欢没关系学生。  Target Label : 0  Prediction Label : 1  \n",
            "\n",
            "Sentence : 杯子谁桌子上吗。  Target Label : 0  Prediction Label : 0  \n",
            "\n",
            "# of sentences:  7\n",
            "Final Mode Accuracy: 0.8482142857142857\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQzI4kUUGUCw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}